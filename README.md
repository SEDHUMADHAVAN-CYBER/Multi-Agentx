# ğŸ§  Multiâ€‘Agent RL Style System using LangGraph & Groq

This project demonstrates a multiâ€‘agent system built using **LangGraph**, powered by the **Groq LLM API**, and enhanced with **RLâ€‘style reward scoring**, **memory**, and optional **negotiation logic**.

## ğŸš€ Features
- Multi-agent architecture:
  - Planner Agent
  - Collaborator Agent
  - Competitor Agent
  - Negotiation Agent (optional)
  - Judge Agent (with reward scoring)
  - Memory Agent (optional)
- RLâ€‘style numeric rewards (1â€“10)
- Selfâ€‘improving loop (training until reward threshold)
- Works on Google Colab
- Fast inference using Groq (Llamaâ€‘3.1â€‘8Bâ€‘Instant)

---

## ğŸ“¦ Installation

```bash
pip install -q langgraph langchain-groq

ğŸ”‘ Setup Groq API Key (in Google Colab)
Go to:

Runtime â†’ Change runtime â†’ Secrets
Add:

GROQ_API_KEY = your_api_key_here

ğŸ—ï¸ Agent Architecture
Planner
   â”œâ”€â”€ Collaborator â†’  
   â”‚                   â”€â”€â†’ Negotiator â†’ Judge â†’ Memory
   â””â”€â”€ Competitor  â†’

â–¶ï¸ Running the Graph
state = {"user_input": "What is anesthesia?"}

final_state = multi_agent_graph.invoke(state)

print(final_state["final_output"])
print(final_state["reward"])
print(final_state["reward_score"])

 Optional: Selfâ€‘Improving RL Loop
train_until_good_answer("What is anesthesia?", threshold=8)

ğŸ“ Project Structure
/project
  â”œâ”€â”€ README.md
  â”œâ”€â”€ multi_agent.ipynb
  â””â”€â”€ requirements.txt
